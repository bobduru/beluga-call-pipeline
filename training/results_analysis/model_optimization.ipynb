{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model optimization results analysis\n",
    "\n",
    "### This file handles the results of the model optimization results done in `run_experiments.ipynb`, and generates the table seen in the paper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/emmanuel/Documents/belugas/beluga-call-pipeline\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Walk up until we find the project root (folder with the .env)\n",
    "current_path = Path().resolve()\n",
    "for parent in [current_path] + list(current_path.parents):\n",
    "    if (parent / \".env\").exists():\n",
    "        load_dotenv(parent / \".env\")\n",
    "        project_root = os.getenv(\"PROJECT_ROOT\")\n",
    "        print(project_root)\n",
    "        sys.path.append(project_root)     \n",
    "        break\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from training.utils import calculate_detection_f1\n",
    "\n",
    "pd.set_option('display.max_columns', None) \n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.utils import aggregate_folds_testing_metrics\n",
    "\n",
    "\n",
    "results_dir = \"../results/model_optimization\"  \n",
    "runs = [d for d in os.listdir(results_dir) if os.path.isdir(os.path.join(results_dir, d))]\n",
    "runs\n",
    "\n",
    "# Load cross validation results for each run\n",
    "cross_val_results = {}\n",
    "for run in runs:\n",
    "\n",
    "    aggregate_folds_testing_metrics(f\"{results_dir}/{run}\")\n",
    "    res_obj = {}\n",
    "    results_path = os.path.join(results_dir, run, \"cross_val_test_results.json\")\n",
    "    if os.path.exists(results_path):\n",
    "        with open(results_path, 'r') as f:\n",
    "            res_obj[\"test_results\"] = json.load(f)\n",
    "\n",
    "    if os.path.exists(os.path.join(results_dir, run, \"test_predictions.csv\")):\n",
    "        res_obj[\"test_predictions_df\"] = pd.read_csv(os.path.join(results_dir, run, \"test_predictions.csv\"))\n",
    "        cross_val_results[run] = res_obj\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_metrics_df(cross_val_results, round_to=3):\n",
    "    # Define the metrics and categories we want to track\n",
    "    metrics = ['f1', 'precision', 'recall', 'accuracy']\n",
    "    categories = ['Labels_Average', 'ECHO', 'HFPC', \"CC\", 'Whistle']\n",
    "    \n",
    "    # Initialize list to store all metrics\n",
    "    metrics_list = []\n",
    "    for run, res_obj in cross_val_results.items():\n",
    "        test_results = res_obj[\"test_results\"]\n",
    "        test_predictions_df = res_obj[\"test_predictions_df\"]\n",
    "\n",
    "        # Calculate detection F1\n",
    "        detection_f1 = calculate_detection_f1(test_predictions_df)\n",
    "        \n",
    "        # Process main results\n",
    "        main_metric_row = {\n",
    "            'run': run,\n",
    "            'test_type': 'fp32',\n",
    "            'detection_f1': round(detection_f1[\"mean\"], round_to),\n",
    "            'detection_f1_std': round(detection_f1[\"std\"], round_to),\n",
    "            'model_size_mb': round(test_results['model_info']['model_size_mb'],2) if test_results['model_info'] and test_results['model_info']['model_size_mb'] is not None else None,\n",
    "            'model_size_kb': round(test_results['model_info']['model_size_kb']) if test_results['model_info'] and test_results['model_info']['model_size_kb'] is not None else None,\n",
    "        }\n",
    "        \n",
    "        # Add main results metrics\n",
    "        for metric in metrics:\n",
    "            for category in categories:\n",
    "                base_name = f\"{category}_{metric}\" if category != 'Labels_Average' else metric\n",
    "                main_metric_row[base_name] = round(test_results['main_results'][metric][category]['mean'], round_to)\n",
    "                main_metric_row[f\"{base_name}_std\"] = round(test_results['main_results'][metric][category]['std'], round_to)\n",
    "        \n",
    "        metrics_list.append(main_metric_row)\n",
    "        \n",
    "        # Process other tests\n",
    "        for test_name, test_metrics in test_results['other_tests'].items():\n",
    "            other_metric_row = {\n",
    "                'run': run,\n",
    "                'test_type': test_name,\n",
    "                'detection_f1': round(detection_f1[\"mean\"], 3),  # Keep the same detection F1\n",
    "                'detection_f1_std': round(detection_f1[\"std\"], 3)\n",
    "            }\n",
    "            if test_name == \"quantized\":\n",
    "                other_metric_row['model_size_mb'] = round(test_results['model_info']['quantized_model_size_mb'],2)\n",
    "                other_metric_row['model_size_kb'] = round(test_results['model_info']['quantized_model_size_kb'])\n",
    "            \n",
    "            # Add other test metrics\n",
    "            for metric in metrics:\n",
    "                for category in categories:\n",
    "                    base_name = f\"{category}_{metric}\" if category != 'Labels_Average' else metric\n",
    "                    other_metric_row[base_name] = round(test_metrics[metric][category]['mean'], round_to)\n",
    "                    other_metric_row[f\"{base_name}_std\"] = round(test_metrics[metric][category]['std'], round_to)\n",
    "            \n",
    "            metrics_list.append(other_metric_row)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(metrics_list)\n",
    "    \n",
    "    # Reorder columns to have run and test_type first\n",
    "    cols = df.columns.tolist()\n",
    "    cols.remove('run')\n",
    "    cols.remove('test_type')\n",
    "    df = df[['run', 'test_type',] + cols]\n",
    "    \n",
    "    return df\n",
    "\n",
    "metrics_df = create_metrics_df(cross_val_results, round_to=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>test_type</th>\n",
       "      <th>model_size_mb</th>\n",
       "      <th>model_size_kb</th>\n",
       "      <th>detection_f1</th>\n",
       "      <th>detection_f1_std</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_std</th>\n",
       "      <th>ECHO_f1</th>\n",
       "      <th>ECHO_f1_std</th>\n",
       "      <th>HFPC_f1</th>\n",
       "      <th>HFPC_f1_std</th>\n",
       "      <th>CC_f1</th>\n",
       "      <th>CC_f1_std</th>\n",
       "      <th>Whistle_f1</th>\n",
       "      <th>Whistle_f1_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>resnet_hp_200_resize</td>\n",
       "      <td>fp32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mobile_net_quant_pretrained_qat_10_layers</td>\n",
       "      <td>fp32</td>\n",
       "      <td>2.96</td>\n",
       "      <td>2892.0</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.911</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mobile_net_quant_pretrained_qat_10_layers</td>\n",
       "      <td>quantized</td>\n",
       "      <td>0.83</td>\n",
       "      <td>807.0</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>mobile_net_quant_pretrained_qat_6_layers</td>\n",
       "      <td>fp32</td>\n",
       "      <td>0.89</td>\n",
       "      <td>871.0</td>\n",
       "      <td>0.967</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mobile_net_quant_pretrained_qat_6_layers</td>\n",
       "      <td>quantized</td>\n",
       "      <td>0.26</td>\n",
       "      <td>252.0</td>\n",
       "      <td>0.967</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>mobile_net_quant_pretrained_qat_8_layers</td>\n",
       "      <td>fp32</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1188.0</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>mobile_net_quant_pretrained_qat_8_layers</td>\n",
       "      <td>quantized</td>\n",
       "      <td>0.35</td>\n",
       "      <td>343.0</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.922</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>mobile_net_quant_pretrained_qat_4_layers</td>\n",
       "      <td>fp32</td>\n",
       "      <td>0.31</td>\n",
       "      <td>304.0</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.801</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>mobile_net_quant_pretrained_qat_4_layers</td>\n",
       "      <td>quantized</td>\n",
       "      <td>0.09</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>mobile_net_quant_pretrained_qat</td>\n",
       "      <td>fp32</td>\n",
       "      <td>4.96</td>\n",
       "      <td>4847.0</td>\n",
       "      <td>0.962</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.922</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.921</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.911</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>mobile_net_quant_pretrained_qat</td>\n",
       "      <td>quantized</td>\n",
       "      <td>1.36</td>\n",
       "      <td>1328.0</td>\n",
       "      <td>0.962</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>mobile_net_quant_pretrained_qat_2_layers</td>\n",
       "      <td>fp32</td>\n",
       "      <td>0.14</td>\n",
       "      <td>136.0</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.506</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>mobile_net_quant_pretrained_qat_2_layers</td>\n",
       "      <td>quantized</td>\n",
       "      <td>0.04</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          run  test_type  model_size_mb  \\\n",
       "0                        resnet_hp_200_resize       fp32            NaN   \n",
       "9   mobile_net_quant_pretrained_qat_10_layers       fp32           2.96   \n",
       "10  mobile_net_quant_pretrained_qat_10_layers  quantized           0.83   \n",
       "16   mobile_net_quant_pretrained_qat_6_layers       fp32           0.89   \n",
       "17   mobile_net_quant_pretrained_qat_6_layers  quantized           0.26   \n",
       "21   mobile_net_quant_pretrained_qat_8_layers       fp32           1.22   \n",
       "22   mobile_net_quant_pretrained_qat_8_layers  quantized           0.35   \n",
       "23   mobile_net_quant_pretrained_qat_4_layers       fp32           0.31   \n",
       "24   mobile_net_quant_pretrained_qat_4_layers  quantized           0.09   \n",
       "27            mobile_net_quant_pretrained_qat       fp32           4.96   \n",
       "28            mobile_net_quant_pretrained_qat  quantized           1.36   \n",
       "33   mobile_net_quant_pretrained_qat_2_layers       fp32           0.14   \n",
       "34   mobile_net_quant_pretrained_qat_2_layers  quantized           0.04   \n",
       "\n",
       "    model_size_kb  detection_f1  detection_f1_std     f1  f1_std  ECHO_f1  \\\n",
       "0             NaN         0.965             0.003  0.924   0.005    0.928   \n",
       "9          2892.0         0.963             0.007  0.924   0.004    0.925   \n",
       "10          807.0         0.963             0.007  0.926   0.003    0.925   \n",
       "16          871.0         0.967             0.004  0.919   0.005    0.923   \n",
       "17          252.0         0.967             0.004  0.917   0.003    0.917   \n",
       "21         1188.0         0.965             0.003  0.926   0.006    0.927   \n",
       "22          343.0         0.965             0.003  0.927   0.006    0.925   \n",
       "23          304.0         0.945             0.005  0.865   0.008    0.894   \n",
       "24           90.0         0.945             0.005  0.860   0.011    0.889   \n",
       "27         4847.0         0.962             0.008  0.926   0.006    0.922   \n",
       "28         1328.0         0.962             0.008  0.924   0.006    0.923   \n",
       "33          136.0         0.848             0.012  0.698   0.024    0.788   \n",
       "34           41.0         0.848             0.012  0.692   0.025    0.784   \n",
       "\n",
       "    ECHO_f1_std  HFPC_f1  HFPC_f1_std  CC_f1  CC_f1_std  Whistle_f1  \\\n",
       "0         0.008    0.902        0.015  0.917      0.008       0.949   \n",
       "9         0.005    0.912        0.012  0.911      0.016       0.949   \n",
       "10        0.005    0.917        0.009  0.915      0.011       0.947   \n",
       "16        0.007    0.904        0.008  0.902      0.008       0.950   \n",
       "17        0.007    0.904        0.015  0.901      0.012       0.948   \n",
       "21        0.004    0.920        0.011  0.908      0.012       0.951   \n",
       "22        0.004    0.922        0.010  0.907      0.009       0.953   \n",
       "23        0.012    0.840        0.016  0.801      0.018       0.925   \n",
       "24        0.017    0.833        0.012  0.792      0.026       0.925   \n",
       "27        0.006    0.921        0.016  0.911      0.011       0.948   \n",
       "28        0.007    0.918        0.012  0.908      0.014       0.948   \n",
       "33        0.020    0.506        0.070  0.629      0.027       0.869   \n",
       "34        0.022    0.497        0.088  0.620      0.036       0.866   \n",
       "\n",
       "    Whistle_f1_std  \n",
       "0            0.004  \n",
       "9            0.005  \n",
       "10           0.004  \n",
       "16           0.007  \n",
       "17           0.004  \n",
       "21           0.003  \n",
       "22           0.006  \n",
       "23           0.002  \n",
       "24           0.004  \n",
       "27           0.004  \n",
       "28           0.004  \n",
       "33           0.011  \n",
       "34           0.005  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df = metrics_df[metrics_df[\"run\"].str.contains(\"qat|resnet\")]\n",
    "\n",
    "f1_columns = ['run', 'test_type', 'model_size_mb', 'model_size_kb']  +[col for col in metrics_df.columns if 'f1' in col.lower()]\n",
    "accuracy_columns = ['run', 'test_type', 'model_size_mb', 'model_size_kb']  +[col for col in metrics_df.columns if 'accuracy' in col.lower()]\n",
    "\n",
    "# Display metrics with only f1-related columns\n",
    "metrics_df[f1_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df[~metrics_df['run'].str.contains('000', na=False)][f1_columns].sort_values('f1', ascending=False)\n",
    "metrics_df[~metrics_df['run'].str.contains('000', na=False)][accuracy_columns].sort_values('accuracy', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
